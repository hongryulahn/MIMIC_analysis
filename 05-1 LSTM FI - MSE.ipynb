{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "483605a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os\n",
    "import pandas as pd\n",
    "\n",
    "# import optuna\n",
    "\n",
    "# https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/274717 \n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.preprocessing import RobustScaler, normalize\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, KFold\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1304d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6182, 10, 4069), (6182,), (1545, 10, 4069), (1545,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random    \n",
    "seed_num = 42\n",
    "random.seed(seed_num)\n",
    "\n",
    "x = np.load('/project/LSH/x_(7727,10,4069).npy')\n",
    "y = np.load('/project/LSH/y_(7727,1).npy')\n",
    "\n",
    "idx = list(range(len(x)))\n",
    "random.shuffle(idx)\n",
    "\n",
    "i = round(x.shape[0]*0.8)\n",
    "X_train, y_train = x[idx[:i],:,:], y[idx[:i]]\n",
    "X_test, y_test = x[idx[i:],:,:], y[idx[i:]]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "749693af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "37/37 [==============================] - 5s 119ms/step - loss: 0.3664 - acc: 0.8557 - val_loss: 0.5126 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51263, saving model to test.hdf5\n",
      "Epoch 2/500\n",
      "37/37 [==============================] - 4s 111ms/step - loss: 0.3316 - acc: 0.8790 - val_loss: 0.5358 - val_acc: 0.7749\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.51263\n",
      "Epoch 3/500\n",
      "37/37 [==============================] - 4s 109ms/step - loss: 0.3102 - acc: 0.8932 - val_loss: 0.5593 - val_acc: 0.7743\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.51263\n",
      "Epoch 4/500\n",
      "37/37 [==============================] - 4s 108ms/step - loss: 0.2843 - acc: 0.9053 - val_loss: 0.5894 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.51263\n",
      "Epoch 5/500\n",
      "37/37 [==============================] - 4s 110ms/step - loss: 0.2693 - acc: 0.9154 - val_loss: 0.6047 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51263\n",
      "Epoch 6/500\n",
      "37/37 [==============================] - 4s 107ms/step - loss: 0.2557 - acc: 0.9178 - val_loss: 0.6592 - val_acc: 0.7367\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51263\n",
      "Epoch 00006: early stopping\n",
      " Computing LSTM feature importance...\n"
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = f\"test.hdf5\"\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "sv = keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None\n",
    ")\n",
    "        \n",
    "history = lstm.fit(X_train, y_train, validation_split=0.25, batch_size=128, epochs=ep, callbacks=[lr, es, sv], shuffle=False)\n",
    "\n",
    "results = []\n",
    "print(' Computing LSTM feature importance...')\n",
    "\n",
    "# COMPUTE BASELINE (NO SHUFFLE)\n",
    "oof_preds = lstm.predict(X_test, verbose=0)\n",
    "baseline_mse = np.square(np.subtract(oof_preds,y_test)).mean()\n",
    "results.append({'feature':'BASELINE','baseline_mse':baseline_mse}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273f4d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3014e417265424ebcd5e7f8bd75c107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4069 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        oof_preds = lstm.predict(X_test, verbose=0)\n",
    "        mse = np.square(np.subtract(oof_preds,y_test)).mean()\n",
    "\n",
    "        results.append({'feature':COLS[k],'mse':mse})\n",
    "        X_test[:,:,k] = save_col\n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "    #     print()\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19611d55",
   "metadata": {},
   "source": [
    "# binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428be6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "        \n",
    "history = lstm.fit(X_train, y_train, validation_split=0.25, batch_size=128, epochs=ep, callbacks=[lr, es], shuffle=False)\n",
    "\n",
    "results = []\n",
    "print(' Computing LSTM feature importance...')\n",
    "\n",
    "# COMPUTE BASELINE (NO SHUFFLE)\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "oof_preds = lstm.predict(X_test, verbose=0)\n",
    "baseline_bce = BinaryCrossentropy(y_test, oof_preds)\n",
    "results.append({'feature':'BASELINE','baseline_bce':baseline_bce}) \n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        oof_preds = lstm.predict(X_test, verbose=0)\n",
    "        bce = BinaryCrossentropy(y_test, oof_preds)\n",
    "\n",
    "        results.append({'feature':COLS[k],'mse':bce})\n",
    "        X_test[:,:,k] = save_col\n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "    #     print()\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('bce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ea142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bfe659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e39f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa3c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099740d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f8229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "\n",
    "seed_num = 42\n",
    "tf.random.set_seed(seed_num)\n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm.add(LSTM(units=128, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(units=64, activation='hard_sigmoid', return_sequences=True))\n",
    "lstm.add(LSTM(units=32, activation='hard_sigmoid', return_sequences=False))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "ep = 500\n",
    "pa = 30\n",
    "early_stop = EarlyStopping(monitor='val_acc', patience=pa, verbose=1, restore_best_weights=True)\n",
    "lstm.compile(optimizer= \"adam\", loss = \"binary_crossentropy\", metrics=['acc'])\n",
    "\n",
    "results = []\n",
    "\n",
    "# COLS\n",
    "a = pd.read_csv('total_data.csv')\n",
    "COLS = list(a['ITEMID'].sort_values().unique())\n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with gpu_strategy.scope():\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        oof_preds = lstm.predict(X_test, verbose=0)\n",
    "        mae = np.mean(np.abs( oof_preds-y_test ))\n",
    "\n",
    "        results.append({'feature':COLS[k],'mae':mae})\n",
    "        X_test[:,:,k] = save_col\n",
    "        \n",
    "        # DISPLAY LSTM FEATURE IMPORTANCE\n",
    "        df = pd.DataFrame(results)\n",
    "        df = df.sort_values('mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54425bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde5007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3924ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ea6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ca709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddbd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행이 잘 안됨\n",
    "EPOCH = 300\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "gpu_strategy = tf.distribute.get_strategy()\n",
    "\n",
    "with gpu_strategy.scope():\n",
    "    test_preds = []\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(X_train.shape[1],X_train.shape[2])),\n",
    "        keras.layers.LSTM(128, activation='hard_sigmoid', return_sequences=True),\n",
    "        keras.layers.LSTM(64, activation='hard_sigmoid', return_sequences=True),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.LSTM(64, activation='hard_sigmoid', return_sequences=True),\n",
    "        keras.layers.LSTM(32, activation='hard_sigmoid', return_sequences=False),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid')])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "    lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=10, verbose=1)\n",
    "    es = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, mode=\"min\", restore_best_weights=True)\n",
    "    sv = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True,\n",
    "        save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "        options=None\n",
    "    )\n",
    "    model.fit(X_train, y_train, validation_split=0.25,epochs=EPOCH, batch_size=BATCH_SIZE, callbacks=[lr, es, sv])\n",
    "\n",
    "\n",
    "    print(' Predicting test data...')\n",
    "    test_preds.append(model.predict(X_test,verbose=0).reshape(-1, 1))\n",
    "\n",
    "    results = []\n",
    "    print(' Computing LSTM feature importance...')\n",
    "\n",
    "    # COMPUTE BASELINE (NO SHUFFLE)\n",
    "    oof_preds = model.predict(X_test, verbose=0)  \n",
    "    baseline_mae = np.mean(np.abs( oof_preds-y_test ))\n",
    "    results.append({'feature':'BASELINE','mae':baseline_mae})           \n",
    "\n",
    "    for k in tqdm(range(len(COLS))):\n",
    "\n",
    "        # SHUFFLE FEATURE K\n",
    "        save_col = X_test[:,:,k].copy()\n",
    "        np.random.shuffle(X_test[:,:,k])\n",
    "\n",
    "        # COMPUTE OOF MAE WITH FEATURE K SHUFFLED\n",
    "        oof_preds = model.predict(X_test, verbose=0)\n",
    "        mae = np.mean(np.abs( oof_preds-y_test ))\n",
    "        results.append({'feature':COLS[k],'mae':mae})\n",
    "        X_test[:,:,k] = save_col\n",
    "\n",
    "        # SAVE LSTM FEATURE IMPORTANCE\n",
    "        df = df.sort_values('mae',ascending=False)\n",
    "        df.to_csv(f'lstm_feature_importance_fold_{fold+1}.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
